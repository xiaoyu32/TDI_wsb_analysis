{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from operator import itemgetter \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission/posts.json') as file:\n",
    "    data = file.read()\n",
    "    new_data = data.replace('}{', '},{')\n",
    "    json_data = json.loads(f'[{new_data}]')\n",
    "    \n",
    "submission = pd.DataFrame.from_records(json_data)\n",
    "\n",
    "submission_timed = submission\n",
    "submission_timed['time'] = pd.to_datetime(submission['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = ['GME', 'AMC','NAKD']\n",
    "close = {}\n",
    "\n",
    "\n",
    "for stock in stock_list:\n",
    "    raw = pd.read_csv('stocks/'+stock+'.csv')\n",
    "    timed = raw \n",
    "    timed['Date'] = pd.to_datetime(timed['Date'])\n",
    "\n",
    "    date = np.array(raw['Date'].to_list()[:-1])\n",
    "    close[stock] = np.array(raw['Adj Close'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_gme = submission_timed[submission_timed['title'].str.lower().str.contains('gme')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "gme_up_date = date[close['GME'][1:] - close['GME'][:-1] >= 0]\n",
    "gme_down_date = date[close['GME'][1:] - close['GME'][:-1] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "gme_date = np.concatenate((gme_up_date,gme_down_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2submission = {}\n",
    "\n",
    "for date in gme_date:\n",
    "    date2submission[date] = submission_gme[submission_gme['time'] == date]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "date2title = {}\n",
    "stop_words = set(stopwords.words('english')) \n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "#tokenizer = nltk.tokenize.casual.TweetTokenizer()\n",
    "word_set = set()\n",
    "\n",
    "for date in gme_date:\n",
    "    title_str = date2submission[date]['title'].str.cat(sep=' ') \n",
    "    text_str = date2submission[date]['text'].str.cat(sep=' ')\n",
    "    author_str = date2submission[date]['author'].str.cat(sep=' ')\n",
    "    string = title_str +' ' +text_str + ' '+ author_str\n",
    "    words = tokenizer.tokenize(string)\n",
    "    words_filtered = [w.lower() for w in words if w.isalpha() and not w.lower() in stop_words]\n",
    "    word_set.update(words_filtered)\n",
    "    word_freq = nltk.FreqDist(words_filtered)\n",
    "    date2title[date] = word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "index2word = {}\n",
    "date2index = {}\n",
    "for i, word in enumerate(word_set):\n",
    "    word2index[word] = i\n",
    "    index2word[i] = word\n",
    "    \n",
    "for i, date in enumerate(gme_date):\n",
    "    date2index[date] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(word2index)\n",
    "n_dates = len(gme_date)\n",
    "\n",
    "wordCount = np.zeros((n_dates, n_words))\n",
    "label = np.zeros((n_dates,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in gme_date:\n",
    "    date_idx = date2index[date]\n",
    "    if date in gme_up_date:\n",
    "        label[date_idx] = 1\n",
    "    \n",
    "    for word in date2title[date]:        \n",
    "        word_idx = word2index[word]\n",
    "        wordCount[date_idx][word_idx] = date2title[date][word]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wordCount\n",
    "y = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 55014)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=11)\n",
    "scores = cross_val_score(gnb_clf, X, y, cv=cv,scoring='accuracy')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoyu/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xiaoyu/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xiaoyu/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xiaoyu/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xiaoyu/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC()\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=11)\n",
    "scores = cross_val_score(svm_clf, X, y, cv=cv,scoring='accuracy')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "#lr_cv_clf = LogisticRegressionCV(cv=cv, random_state=11,tol=1e-3,max_iter=1000).fit(X, y)\n",
    "lr_cv_clf = LogisticRegressionCV(cv=cv, random_state=11,max_iter=1000,solver='liblinear').fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr_cv_clf, X, y, cv=cv,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6372039072039072\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef2index = {}\n",
    "\n",
    "for i, coef in enumerate(lr_cv_clf.coef_[0]):\n",
    "    coef2index[coef] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_coef2index = sorted(coef2index.items(), key = itemgetter(0), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_predictor = 20\n",
    "\n",
    "top_up_predictor = sort_coef2index[:n_predictor]\n",
    "top_down_predictor = sort_coef2index[-n_predictor:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would 0.19590451740836304\n",
      "sell 0.19016377605053203\n",
      "streamable 0.187513574265436\n",
      "squeeze 0.18567342486440555\n",
      "short 0.18197344576594301\n",
      "red 0.15865192401275535\n",
      "point 0.15016894352503884\n",
      "wsb 0.1499505997962657\n",
      "gt 0.14836546877715365\n",
      "selling 0.14374704274412922\n",
      "investing 0.14022840017979757\n",
      "sold 0.13884275503248675\n",
      "going 0.1326758709227111\n",
      "today 0.12849663204578707\n",
      "sne 0.12598808686434826\n",
      "trade 0.12429786576299906\n",
      "cohen 0.12360462929703943\n",
      "yolo 0.1131509535145309\n",
      "affectionate 0.11196603200546844\n",
      "ryan 0.11132974438981162\n"
     ]
    }
   ],
   "source": [
    "for predictor in top_up_predictor:\n",
    "    print(index2word[predictor[1]],predictor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puts -0.26638915672364716\n",
      "next -0.2663100284488798\n",
      "keep -0.1841075682522767\n",
      "words -0.18409267823392597\n",
      "us -0.1777961119068264\n",
      "buying -0.17654669224431463\n",
      "calls -0.16998247709154093\n",
      "holders -0.16459610706089917\n",
      "reggie -0.1551772046667154\n",
      "ontologicala -0.15453406629592767\n",
      "thoughts -0.15191225561898158\n",
      "bought -0.14953719500289897\n",
      "open -0.13976732891140306\n",
      "im -0.13947473128622537\n",
      "interest -0.13718162536781023\n",
      "shit -0.13632714134764096\n",
      "ragnarok -0.13549781186349646\n",
      "baitmanz -0.13549502213773099\n",
      "jan -0.13312002876272286\n",
      "way -0.1299717078691803\n"
     ]
    }
   ],
   "source": [
    "for predictor in top_down_predictor[::-1]:\n",
    "    print(index2word[predictor[1]],predictor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
